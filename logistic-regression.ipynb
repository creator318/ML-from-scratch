{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression from scratch using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation = $\\hat y = h_\\theta(x) = \\frac 1 {1 + e^{-wx + b}}$\n",
    " - sigmoid function $\\sigma(x) = \\dfrac 1 {1 + e^{-x}}$\n",
    "\n",
    "Error = $\\text{Cross Entropy} = J(w, b) = J(\\theta) = \\dfrac 1 n \\displaystyle \\sum_{i=1}^n\\large{[y_i \\cdot log(h_\\theta(x_i)) + (1 + y_i) \\cdot log(1 - h_\\theta(x_i))]}$ \n",
    " - Derivative of error $J'(w, b) = J'(\\theta) = \\begin{bmatrix} \\dfrac{dJ}{dw} \\\\ \\\\ \\dfrac{dJ}{db} \\end{bmatrix} = \\begin{bmatrix} \\dfrac 1 n \\sum{2x_i (\\hat y - y_i)} \\\\ \\\\ \\dfrac 1 n \\sum{2 (\\hat y - y_i)} \\end{bmatrix}$\n",
    "\n",
    "Gradient descent\n",
    " - $w = w - \\alpha\\cdot dw$\n",
    " - $b = b - \\alpha\\cdot db$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "  def __init__(self, alpha=0.001, epochs=1000):\n",
    "    self.alpha = alpha\n",
    "    self.epochs = epochs\n",
    "    self.w = None\n",
    "    self.b = None\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    nSamples, nFeatures = X.shape\n",
    "    self.w = np.random.randn(nFeatures)\n",
    "    self.b = np.random.random()\n",
    "\n",
    "    for _ in range(self.epochs):\n",
    "      linearPred = np.dot(X, self.w) + self.b\n",
    "      yPred = sigmoid(linearPred)\n",
    "\n",
    "      dw = 1/nSamples * np.dot(X.T, (yPred - y))\n",
    "      db = 1/nSamples * np.sum(yPred - y)\n",
    "      self.w -= self.alpha * dw\n",
    "      self.b -= self.alpha * db\n",
    "\n",
    "  def predict(self, X):\n",
    "    linearPred = np.dot(X, self.w) + self.b\n",
    "    yPred = sigmoid(linearPred)\n",
    "    return [0 if y<0.5 else 1 for y in yPred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_383550/449343092.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "breastCancer = datasets.load_breast_cancer()\n",
    "X, y = breastCancer.data, breastCancer.target\n",
    "\n",
    "XTrain, XTest, YTrain, YTest = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = LogisticRegression(alpha=0.01)\n",
    "classifier.fit(XTrain, YTrain)\n",
    "predictions = classifier.predict(XTest)\n",
    "\n",
    "\n",
    "def accuracy(yTest, yPred):\n",
    "  return np.sum(yTest == yPred) / len(yTest)\n",
    "\n",
    "\n",
    "acc = accuracy(YTest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9298245614035088)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
